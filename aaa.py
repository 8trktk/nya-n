{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "実験.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4fBxhmFwEy3+LGp5PuuXO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eidkbQ-ZaD6_",
        "colab_type": "text"
      },
      "source": [
        "準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Uftq_naGVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torch.nn.functional import linear\n",
        "from torch.nn.modules import Linear"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf00N8IjaCOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Union\n",
        "from math import floor\n",
        "\n",
        "def percentile(t: torch.tensor, q: float) -> Union[int, float]:\n",
        "    k = 1 + floor(.01 * float(q) * (t.numel() - 1))\n",
        "    result = t.view(-1).kthvalue(k).values.item()\n",
        "    return result"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wpncr02Y5og",
        "colab_type": "text"
      },
      "source": [
        "Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9QWz_99P529",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Independent_WeightBias_Rate_LinearFunction(Function):\n",
        "    \"\"\"独立％のLinearFunction\n",
        "    更新するニューロンをレイヤ内からn％選ぶ(n=√n ,25, 50, 75), またレイヤ間の従属関係はない\n",
        "    更新するニューロンは重みとバイアスの勾配から決定する\n",
        "    勾配の絶対値から大きな値を上位n％個選び更新する\n",
        "    \"\"\"  \n",
        "    @staticmethod\n",
        "    def forward(ctx, x, w, b=None, rate=100):\n",
        "        rate = torch.as_tensor(rate).requires_grad_(False)\n",
        "        ctx.save_for_backward(x, w, b, rate)\n",
        "        return linear(x, w, b)\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx,grad_out):\n",
        "        x, w, b, rate = ctx.saved_tensors\n",
        "        # 勾配計算\n",
        "        grad_x = grad_out.mm(w)\n",
        "        grad_w = grad_out.t().mm(x)\n",
        "        grad_b = grad_out.sum(0)\n",
        "        \n",
        "        if 0 <= rate < 100:\n",
        "            g_w = grad_w.clone()\n",
        "            g_b = grad_b.clone()\n",
        "            g_cat = torch.cat((g_w, g_b.unsqueeze(0).T), 1).abs()\n",
        "            # 絶対値の上位n％値を計算\n",
        "            g_rate = percentile(g_cat, 100-rate)\n",
        "            # マスクを作る\n",
        "            w_msk = g_w.abs() <= g_rate\n",
        "            b_msk = g_b.abs() <= g_rate\n",
        "            # 更新するニューロンを選択\n",
        "            if torch.sum(w_msk) != w_msk.numel():\n",
        "                grad_w = grad_w.masked_fill(w_msk, 0)\n",
        "            else:\n",
        "                grad_w = torch.zeros(grad_w.shape, dtype=torch.float)\n",
        "            if torch.sum(b_msk) != b_msk.numel():\n",
        "                grad_b = grad_b.masked_fill(b_msk, 0)\n",
        "            else:\n",
        "                grad_b = torch.zeros(grad_b.shape, dtype=torch.float)\n",
        "        # 例外処理\n",
        "        if not ctx.needs_input_grad[0]:\n",
        "            grad_x = None\n",
        "        if not ctx.needs_input_grad[1]:\n",
        "            grad_w = None\n",
        "        if type(b) != torch.Tensor or not ctx.needs_input_grad[2]:\n",
        "            grad_b = None\n",
        "        return grad_x, grad_w, grad_b, None"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5y2oSkLaz7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Independent_Neuron_Rate_LinearFunction(Function):\n",
        "    \"\"\"独立％のLinearFunction\n",
        "    更新するニューロンをレイヤ内からn％選ぶ(n=√n ,25, 50, 75, 100), またレイヤ間の従属関係はない\n",
        "    更新するニューロンは重みとバイアスの勾配から決定する\n",
        "    勾配の絶対値から大きな値を上位n％個選び更新する\n",
        "    \"\"\"  \n",
        "    @staticmethod\n",
        "    def forward(ctx, x, w, b=None, rate=100):\n",
        "        rate = torch.as_tensor(rate).requires_grad_(False)\n",
        "        ctx.save_for_backward(x, w, b, rate)\n",
        "        return linear(x, w, b)\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx,grad_out):\n",
        "        x, w, b, rate = ctx.saved_tensors\n",
        "        # 勾配計算\n",
        "        grad_x = grad_out.mm(w)\n",
        "        grad_w = grad_out.t().mm(x)\n",
        "        grad_b = grad_out.sum(0)\n",
        "        # 後で計算に使うマスク(形状がgrad_wで全要素がFalse)\n",
        "        false_msk = grad_w.abs() < 0\n",
        "\n",
        "        if 0 <= rate < 100:\n",
        "            g_w = grad_w.clone()\n",
        "            g_b = grad_b.clone()\n",
        "            g_cat = torch.cat((g_w, g_b.unsqueeze(0).T), 1).abs()\n",
        "            # ニューロンごとに勾配の合計を計算する\n",
        "            g_sum = torch.sum(g_cat, axis=1)\n",
        "            # 絶対値の上位n％値を計算\n",
        "            g_rate = percentile(g_sum, 100-rate)\n",
        "            # マスクを作る\n",
        "            b_msk = g_sum <= g_rate\n",
        "            w_msk = b_msk.unsqueeze(0).T + false_msk\n",
        "            # 更新するニューロンを選択\n",
        "            if torch.sum(w_msk) != w_msk.numel():\n",
        "                grad_w = grad_w.masked_fill(w_msk, 0)\n",
        "            else:\n",
        "                grad_w = torch.zeros(grad_w.shape, dtype=torch.float)\n",
        "            if torch.sum(b_msk) != b_msk.numel():\n",
        "                grad_b = grad_b.masked_fill(b_msk, 0)\n",
        "            else:\n",
        "                grad_b = torch.zeros(grad_b.shape, dtype=torch.float)\n",
        "\n",
        "        # 例外処理\n",
        "        if not ctx.needs_input_grad[0]:\n",
        "            grad_x = None\n",
        "        if not ctx.needs_input_grad[1]:\n",
        "            grad_w = None\n",
        "        if type(b) != torch.Tensor or not ctx.needs_input_grad[2]:\n",
        "            grad_b = None\n",
        "\n",
        "        return grad_x, grad_w, grad_b, None"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0K9XKfQZE1D",
        "colab_type": "text"
      },
      "source": [
        "Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MVp7Q0ZZFFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Independent_WeightBias_Rate_Linear(Linear):\n",
        "    \"\"\"独立のLinear\n",
        "    独立更新のレイヤー\n",
        "    \"\"\"\n",
        "    def __init__(self, input_feautures, output_features, bias=True, rate=100):\n",
        "        super().__init__(input_feautures, output_features, bias)\n",
        "        self.rate = rate\n",
        "    def forward(self, input):\n",
        "        res = Independent_WeightBias_Rate_LinearFunction.apply(input, self.weight, self.bias, self.rate)\n",
        "        return res"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqLjlbPPa3H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Independent_Neuron_Rate_Linear(Linear):\n",
        "    \"\"\"独立のLinear\n",
        "    独立更新のレイヤー\n",
        "    \"\"\"\n",
        "    def __init__(self, input_feautures, output_features, bias=True, rate=100):\n",
        "        super().__init__(input_feautures, output_features, bias)\n",
        "        self.rate = rate\n",
        "    def forward(self, input):\n",
        "        res = Independent_Neuron_Rate_LinearFunction.apply(input, self.weight, self.bias, self.rate)\n",
        "        return res"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuZbZeuGZi1S",
        "colab_type": "text"
      },
      "source": [
        "実験"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blP_FSQOZjLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "77b1a130-fa68-4f45-b5f9-de3a7b64fd45"
      },
      "source": [
        "from os import getcwd, makedirs\n",
        "from os.path import join, isdir\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "# モデル\n",
        "from torchvision.models import vgg\n",
        "# データセット\n",
        "#from preprocess import cifar10_dataloader as cifar10\n",
        "from procedure.preprocess import cifar10_dataloader as cifar10\n",
        "# tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# save list\n",
        "import pickle\n",
        "import gc\n",
        "\"\"\" 設定パラメータ\"\"\"\n",
        "model_name = \"モデル名\"\n",
        "seed = 0  # ランダムシード\n",
        "gpu = True  # gpu使用フラグ\n",
        "lr = 0.001  # 学習率\n",
        "momentum = 0.9  # モーメンタム\n",
        "epochs = 50  # Epoch数\n",
        "batch_size = 100  # バッチサイズ\n",
        "rate = [1.6, 25, 50, 75, 100][3]\n",
        "writer = SummaryWriter('runs/' + model_name)\n",
        "\n",
        "def main():\n",
        "    global writer, model_name, update_method\n",
        "    # ランダムシード\n",
        "    # PyTorch 以外のRNGを初期化\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    # cuDNNを使用しない (遅くなる?)\n",
        "    cudnn.deterministic = True\n",
        "    # PyTorchのRNGを初期化\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # デバイス設定\n",
        "    if torch.cuda.is_available() and gpu is True:\n",
        "        device = 'cuda'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    # モデルを定義\n",
        "    model = vgg.vgg16()\n",
        "    # 準同期式に変更\n",
        "    model.classifier[0] = Independent_Neuron_Rate_Linear(512*7*7, 4096, True, rate)\n",
        "    model.classifier[3] = Independent_Neuron_Rate_Linear(4096, 4096, True, rate)\n",
        "    model = model.to(device)\n",
        "    # 評価関数\n",
        "    criterion_mean = CrossEntropyLoss().to(device)\n",
        "    criterion_sum = CrossEntropyLoss(reduction='sum').to(device)\n",
        "\n",
        "    # パラメータ更新手法\n",
        "    optimizer = SGD(model.parameters(), lr, momentum=momentum)\n",
        "    # オートチューナーOFF\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Dataset\n",
        "    train_loader, eval_loader = cifar10(random_seed=seed, batch_size=batch_size)\n",
        "    # 評価\n",
        "    evaluate(-1, model, eval_loader, criterion_mean, criterion_sum, device)\n",
        "    # 学習\n",
        "    for epoch in range(epochs):\n",
        "        train(epoch, model, train_loader, optimizer, criterion_mean, criterion_sum, device)\n",
        "        evaluate(epoch, model, eval_loader, criterion_mean, criterion_sum, device)\n",
        "    # 学習結果を保存\n",
        "    save(data=model, name=model_name, task=\"model\")\n",
        "\n",
        "def mkdirs(path):\n",
        "    \"\"\" ディレクトリが無ければ作る \"\"\"\n",
        "    if not isdir(path):\n",
        "        makedirs(path)\n",
        "\n",
        "def save(data, name, task):\n",
        "    \"\"\" SAVE MODEL\n",
        "    data: 保存するデータ\n",
        "    name: ファイル名\n",
        "    task: データのタイプ\n",
        "    \"\"\"\n",
        "    global model_name\n",
        "    save_dir = join(getcwd(), \"log/\" + model_name)\n",
        "    mkdirs(save_dir)\n",
        "    if task == \"model\":\n",
        "        \"\"\" モデルを保存\n",
        "        Memo: ロードする方法\n",
        "        model = TheModelClass(*args, **kwargs)\n",
        "        model.load_state_dict(torch.load(PATH))\n",
        "        model.eval()\n",
        "        \"\"\"\n",
        "        torch.save(data.state_dict(), join(save_dir, name+'.model'))\n",
        "    elif task == \"progress\":\n",
        "        \"\"\" 予測の途中経過\n",
        "        Memo: ロードする方法\n",
        "        data = None\n",
        "        with open(PATH, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        \"\"\"\n",
        "        with open(join(save_dir, name+'.dump'), 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "def evaluate(epoch, model, data_loader, criterion_mean, criterion_sum, device):\n",
        "    \"\"\" 評価用関数 \"\"\"\n",
        "    global writer\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        answers_list = []\n",
        "        outputs_list = []\n",
        "        loss_sum = 0\n",
        "        accuracy_sum = 0\n",
        "        item_counter = 0\n",
        "        for i, (inputs, labels) in enumerate(data_loader):\n",
        "            # デバイス用設定\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # モデルへ適用\n",
        "            outputs = model(inputs)\n",
        "            # lossを計算\n",
        "            # criterion_meanはbackprop/update用\n",
        "            loss = criterion_mean(outputs, labels)\n",
        "            # criterion_sumはログ記録用\n",
        "            loss_sum += criterion_sum(outputs, labels).item()\n",
        "            # accuracyを計算\n",
        "            _, argmax = torch.max(outputs, 1)\n",
        "            accuracy = (labels == argmax.squeeze()).float().sum().item()\n",
        "            accuracy_sum += accuracy\n",
        "            # 画像数\n",
        "            item_counter += len(outputs)\n",
        "            # log\n",
        "            answers_list.append(labels.to('cpu'))\n",
        "            outputs_list.append(outputs.to('cpu'))\n",
        "            # debug\n",
        "            print('progress: [{0}/{1}]\\t'\n",
        "                  'Loss: {loss:.3f}\\t'\n",
        "                  'Accuracy: {accuracy:.3f}'.format(\n",
        "                      i, len(data_loader),\n",
        "                      loss=loss.item(),\n",
        "                      accuracy=accuracy/len(outputs)))\n",
        "        # output log to tensorboard\n",
        "        writer.add_scalar('evaluate loss',\n",
        "                          loss_sum/item_counter,\n",
        "                          epoch)\n",
        "        writer.add_scalar('evaluate Accuracy',\n",
        "                          accuracy_sum/item_counter,\n",
        "                          epoch)\n",
        "        # save log\n",
        "        d = {\n",
        "            \"outputs\": outputs_list,\n",
        "            \"answers\": answers_list\n",
        "        }\n",
        "        n = \"evaluate{}\".format(epoch)\n",
        "        save(data=d, name=n, task=\"progress\")\n",
        "        del answers_list\n",
        "        del outputs_list\n",
        "        gc.collect()\n",
        "\n",
        "def train(epoch, model, data_loader, optimizer, criterion_mean, criterion_sum, device):\n",
        "    \"\"\" 学習用関数 \"\"\"\n",
        "    global writer\n",
        "    model.train()\n",
        "    answers_list = []\n",
        "    outputs_list = []\n",
        "    loss_sum = 0\n",
        "    accuracy_sum = 0\n",
        "    item_counter = 0\n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        # デバイス用設定\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 勾配の初期化\n",
        "        optimizer.zero_grad()\n",
        "        # モデルへ適用\n",
        "        outputs = model(inputs)\n",
        "        # lossを計算\n",
        "        # criterion_meanはbackprop/update用\n",
        "        loss = criterion_mean(outputs, labels)\n",
        "        # criterion_sumはログ記録用\n",
        "        loss_sum += criterion_sum(outputs, labels).item()\n",
        "        # accuracyを計算\n",
        "        _, argmax = torch.max(outputs, 1)\n",
        "        accuracy = (labels == argmax.squeeze()).float().sum().item()\n",
        "        accuracy_sum += accuracy\n",
        "        # 画像数\n",
        "        item_counter += len(outputs)\n",
        "        # 逆伝播\n",
        "        loss.backward()\n",
        "        # パラメータ更新\n",
        "        optimizer.step()\n",
        "        # log\n",
        "        answers_list.append(labels.to('cpu'))\n",
        "        outputs_list.append(outputs.to('cpu'))\n",
        "        # debug\n",
        "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "              'Loss {loss:.4f}\\t'\n",
        "              'Accuracy: {accuracy:.3f}'.format(\n",
        "               epoch, i, len(data_loader),\n",
        "               loss=loss.item(),\n",
        "               accuracy=accuracy/len(outputs)))\n",
        "    # output log to tensorboard\n",
        "    writer.add_scalar('train loss',\n",
        "                      loss_sum/item_counter,\n",
        "                      epoch)\n",
        "    writer.add_scalar('train Accuracy',\n",
        "                      accuracy_sum/item_counter,\n",
        "                      epoch)\n",
        "    # save log\n",
        "    d = {\n",
        "        \"outputs\": outputs_list,\n",
        "        \"answers\": answers_list\n",
        "    }\n",
        "    n = \"train_{}\".format(epoch)\n",
        "    save(data=d, name=n, task=\"progress\")\n",
        "    del answers_list\n",
        "    del outputs_list\n",
        "    gc.collect()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-94adb0bf9b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-94adb0bf9b5a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# 評価\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cifar10' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aHNRP-9lsNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}